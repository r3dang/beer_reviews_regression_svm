{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name: Rajit Dang; PID: A92067342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "import scipy.optimize as opt\n",
    "import random as rand\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "  for l in urllib.request.urlopen(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print (\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_taste_feature = [d['review/taste'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5135699375\n"
     ]
    }
   ],
   "source": [
    "# Q1: Calculating the Variance of taste reviews\n",
    "taste_variance = np.var(review_taste_feature)\n",
    "print(taste_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.92225\n"
     ]
    }
   ],
   "source": [
    "# Q1: Calculating the mean of Taste reviews\n",
    "taste_mean = np.mean(review_taste_feature)\n",
    "print(taste_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find the MSE for a feature\n",
    "def findMSEForFeature(feature):\n",
    "    squared_error = 0\n",
    "    for rating in feature:\n",
    "        rating_error = (rating - taste_mean)**2\n",
    "        squared_error += rating_error\n",
    "    return squared_error/len(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5135699375\n"
     ]
    }
   ],
   "source": [
    "# Calculating the MSE for predicting taste reviews using mean as a predictor.\n",
    "taste_mse = findMSEForFeature(review_taste_feature)\n",
    "print(taste_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What is the variance of the ‘review/taste’ scores in the data? What is the Mean Squared Error (MSE)\n",
    "obtained when predicting the ‘review/taste’ score using the mean value of ‘review/taste’ (1 mark)?\n",
    "\n",
    "Answer: The Variance of the data is 0.0.5135699375 and the Mean Squared Error of prediciting \n",
    "        taste reviews using mean is also 0.0.5135699375."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def writeDataToFile(filename, d):\n",
    "    fileToWrite = open(filename, \"w\")\n",
    "    for x,y in d.items():\n",
    "        fileToWrite.write(x + '\\t' + str(y) + '\\n')\n",
    "    fileToWrite.close()\n",
    "\n",
    "beerStyles = [d['beer/style'] for d in data]\n",
    "setOfBeerStyles = set()\n",
    "styleCounts = {}\n",
    "for style in beerStyles:\n",
    "    if(style in setOfBeerStyles):\n",
    "        styleCounts[style]+= 1\n",
    "        continue\n",
    "    else:\n",
    "        styleCounts[style] = 1\n",
    "        setOfBeerStyles.add(style)\n",
    "# Writing counts of each style to a file which will be submitted on Gradescope\n",
    "writeDataToFile(\"styleCounts.txt\", styleCounts)\n",
    "\n",
    "\n",
    "setOfBeerStyles.clear()\n",
    "# Calculating average for each review\n",
    "styleTasteAverages = {}\n",
    "for d in data:\n",
    "    style = d['beer/style']\n",
    "    tasteReview = d['review/taste']\n",
    "    if style in setOfBeerStyles:\n",
    "        styleTasteAverages[style] += tasteReview\n",
    "    else:\n",
    "        setOfBeerStyles.add(style)\n",
    "        styleTasteAverages[style] = tasteReview\n",
    "\n",
    "for style,review in styleTasteAverages.items():\n",
    "    styleTasteAverages[style] = review/styleCounts[style]\n",
    "\n",
    "writeDataToFile(\"styleAverages.txt\", styleTasteAverages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Average for each style has been written to 'styleAvergaes.txt' and the total number of reviews for each style has been written to 'styleCounts.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression for 'Beer is an American APA'\n",
    "# create feature vector for American APA\n",
    "\n",
    "data2 = [d for d in data if 'beer/style' in d]\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1]\n",
    "  if datum['beer/style'] == \"American IPA\":\n",
    "    feat.append(1)\n",
    "  else:\n",
    "    feat.append(0)\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data2]\n",
    "y = [d['review/taste'] for d in data2]\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Train a simple predictor with a single binary feature indicating whether a beer is an ‘American IPA’:\n",
    "review/taste ' θ0 + θ1 × [beer is an American IPA]\n",
    "Report the values of θ0 and θ1. Briefly describe your interpretation of these values, i.e., what do θ0 and\n",
    "θ1 represent (1 mark)?\n",
    "\n",
    "Answer: θ0 = 3.91520474 and θ1 = 0.08564622. θ0 represents the intercept and θ1 represents the slope. specifically, the intercept value shows the average rating of all other beers besides American IPA, and the slope shows that the average rating for American IPA is 1 * slope better or worse (depending on the sign of the slope) than the average rating for all other beers. Since in this case we are using binary values, the point at the intercept represents the average rating of all other beers, and the point at intercept + 1 * slope represents the average rating of American IPA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into two creating training and test set.\n",
    "trainingSet = data[:25000]\n",
    "testSet = data[25000:]\n",
    "\n",
    "ipaData = [d for d in trainingSet if 'beer/style' in d]\n",
    "\n",
    "X = [feature(d) for d in ipaData]\n",
    "y = [d['review/taste'] for d in ipaData]\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mseTraining = residuals/len(ipaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking accuracy of model on the test set.\n",
    "thetaZero = theta[0]\n",
    "thetaOne = theta[1]\n",
    "\n",
    "\n",
    "\n",
    "# ipaData is now the test data\n",
    "ipaData = [d for d in testSet if 'beer/style' in d]\n",
    "X_test = [feature(d) for d in ipaData]\n",
    "y = np.dot(X_test, theta.T)\n",
    "y = np.matrix(y)\n",
    "y_test = [d['review/taste'] for d in ipaData]\n",
    "mse = np.sum(np.square(y_test - y)) / 25000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Split the data into two equal fractions – the first half for training, the second half for testing (based on\n",
    "the order they appear in the file). Train the same model as above on the training set only. What is the\n",
    "model’s MSE on the training and on the test set (1 mark)?\n",
    "\n",
    "Answer: The MSE for the training set = 0.55810729 and the mse for the test set is 0.468410050967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36677236]\n"
     ]
    }
   ],
   "source": [
    "# Creating Model for all beer styles\n",
    "\n",
    "def createStyleFeature(datum):\n",
    "    feat = [1]\n",
    "    for style in setOfBeerStyles:\n",
    "        if style == 'American Double / Imperial Pilsner':\n",
    "            continue\n",
    "        if(datum['beer/style'] == style):\n",
    "            feat.append(1)\n",
    "        else:\n",
    "            feat.append(0)\n",
    "    return feat\n",
    "\n",
    "styleData = [d for d in data if 'beer/style' in d]\n",
    "trainingSet = styleData[:25000]\n",
    "testSet = styleData[25000:]\n",
    "\n",
    "X = [createStyleFeature(d) for d in trainingSet]\n",
    "y = [d['review/taste'] for d in trainingSet]\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)\n",
    "print (residuals/25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.434410728015\n"
     ]
    }
   ],
   "source": [
    "# Checking MSE for testSet\n",
    "X_test = [createStyleFeature(d) for d in testSet]\n",
    "y = np.dot(X_test, theta.T)\n",
    "y = np.matrix(y)\n",
    "y_test = [d['review/taste'] for d in testSet]\n",
    "mse = np.sum(np.square(y_test - y)) / 25000\n",
    "print (mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Extend the model above so that it incorporates binary features for every style of beer. Report the values of θ that you obtain, and the model’s MSE on the training and on the test set (1 mark).\n",
    "\n",
    "Answer: The MSE for the testSet = 0.434410728015 and the MSE for the trainingSet = 0.36677236."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Beginning WEEK 2 #####\n",
    "\n",
    "def createSVMFeature(datum):\n",
    "    feat = []\n",
    "    feat.append(datum['beer/ABV'])\n",
    "    feat.append(datum['review/taste'])\n",
    "    return feat\n",
    "\n",
    "X_svm = [createSVMFeature(d) for d in trainingSet]\n",
    "y_svm = ['American IPA' in d['beer/style'] for d in trainingSet]\n",
    "\n",
    "X_test_svm = [createSVMFeature(d) for d in testSet]\n",
    "y_test_svm = ['American IPA' in d['beer/style'] for d in testSet]\n",
    "clf = svm.SVC(C = 1000, kernel = 'linear')\n",
    "clf.fit(X_svm, y_svm)\n",
    "\n",
    "train_predictions = clf.predict(X_svm)\n",
    "test_predictions = clf.predict(X_test_svm)\n",
    "\n",
    "match_train = [(x == y) for x,y in zip(y_svm, train_predictions)]\n",
    "match_test = [(x == y) for x,y in zip(y_test_svm, test_predictions)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculating the error for training set\n",
    "sum(match_train) * 1.0/len(match_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(match_test) * 1.0/len(match_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) First, let’s train a predictor that estimates whether a beer is an ‘American IPA’ using two features:\n",
    "[‘beer/ABV’, ‘review/taste’].\n",
    "Train your predictor using an SVM classifier (see the code provided in class) – remember to train on the\n",
    "first half and test on the second half. Use a regularization constant of C = 1000 as in the code stub.\n",
    "What is the accuracy (percentage of correct classifications) of the predictor on the train and test data?\n",
    "(1 mark)\n",
    "\n",
    "Answer: MSE on training set: 0.91295999999999999 and MSE on test Set: 0.92112000000000005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Improving Classifications from 6\n",
    "def createImprovedFeature(datum):\n",
    "    feat = []\n",
    "    if ('India' in datum['beer/name']):\n",
    "        feat.append(1)\n",
    "    else:\n",
    "        feat.append(0)\n",
    "        \n",
    "    if ('IPA' in datum['beer/name']):\n",
    "        feat.append(1)\n",
    "    else:\n",
    "        feat.append(0)\n",
    "    return feat\n",
    "        \n",
    "X_svm = [createImprovedFeature(d) for d in trainingSet]\n",
    "y_svm = ['American IPA' in d['beer/style'] for d in trainingSet]\n",
    "\n",
    "X_test_svm = [createImprovedFeature(d) for d in testSet]\n",
    "y_test_svm = ['American IPA' in d['beer/style'] for d in testSet]\n",
    "clf = svm.SVC(C = 1000, kernel = 'linear')\n",
    "clf.fit(X_svm, y_svm)\n",
    "\n",
    "train_predictions = clf.predict(X_svm)\n",
    "test_predictions = clf.predict(X_test_svm)\n",
    "\n",
    "match_train = [(x == y) for x,y in zip(y_svm, train_predictions)]\n",
    "match_test = [(x == y) for x,y in zip(y_test_svm, test_predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculating the error for training set\n",
    "sum(match_train) * 1.0/len(match_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculating error for the test set\n",
    "sum(match_test) * 1.0/len(match_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Considering the ‘American IPA’ style, can you come up with a more accurate predictor (e.g. using features\n",
    "from the text, or otherwise)? Write down the feature vector you design, and report its train/test accuracy\n",
    "(1 mark).\n",
    "\n",
    "Answer: Training Error: 0.94216 and Test Error: 0.96384000000000003, therefore this model better predicts values. Feature Vector design:\n",
    "if beer/name contains 'IPA' or 'American', then output 1, else output 0, which are binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#8 Change value of C to run for Experiment\n",
    "clf = svm.SVC(C = 0.0001, kernel = 'linear')\n",
    "clf.fit(X_svm, y_svm)\n",
    "\n",
    "train_predictions = clf.predict(X_svm)\n",
    "test_predictions = clf.predict(X_test_svm)\n",
    "\n",
    "match_train = [(x == y) for x,y in zip(y_svm, train_predictions)]\n",
    "match_test = [(x == y) for x,y in zip(y_test_svm, test_predictions)]\n",
    "\n",
    "# calculating the error for training set\n",
    "print(sum(match_train) * 1.0/len(match_train))\n",
    "print(sum(match_test) * 1.0/len(match_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) What effect does the regularization constant C have on the training/test performance? Report the\n",
    "train/test accuracy of your predictor from the previous question for C ∈ h0.1, 10, 1000, 100000i.\n",
    "\n",
    "Answer: Regularization constant has no effect on training test/performance as it is not possible to overfit the data when the size of the data is massive but the number of features being used to make predictions is small. So, no mattter what values of C, the train/test errrors are going to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black IPA', 'Black IPA', 'Black IPA', 'Herkulean IPA', 'Herkulean IPA', 'Herkulean IPA', 'Herkulean IPA', 'Herkulean IPA', 'Herkulean IPA', 'Big Red IPA', 'Kirkwood Station Black Rye IPA', 'First Chance American IPA', 'First Chance American IPA', \"O'Fallon IPA\", \"O'Fallon IPA\", 'Every Day IPA', 'Every Day IPA', 'IPA']\n"
     ]
    }
   ],
   "source": [
    "fathom_ipa = [d['beer/name'] for d in data if d['beer/ABV'] == 6.0 and 'IPA' in d['beer/name']]\n",
    "print (fathom_ipa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
